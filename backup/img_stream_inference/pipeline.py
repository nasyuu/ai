import logging
import os
import sys
import time
from datetime import datetime
from functools import wraps
from pathlib import Path


# é…ç½®æ—¥å¿—ç³»ç»Ÿ
def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)

    log_file = log_dir / f"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

    is_exe = getattr(sys, "frozen", False)

    if is_exe:
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler(log_file, encoding="utf-8"),
            ],
        )
    else:
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler(log_file, encoding="utf-8"),
                logging.StreamHandler(),
            ],
        )
    return logging.getLogger(__name__)


logger = setup_logging()

# å…¨å±€è¿›åº¦å›è°ƒå’Œåœæ­¢æ ‡å¿—
progress_callback = None
stop_requested = False


def set_progress_callback(callback):
    """è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°"""
    global progress_callback
    progress_callback = callback


def request_stop():
    """è¯·æ±‚åœæ­¢æ‰§è¡Œ"""
    global stop_requested
    stop_requested = True


def reset_stop_flag():
    """é‡ç½®åœæ­¢æ ‡å¿—"""
    global stop_requested
    stop_requested = False


def update_progress(step_name, progress):
    """æ›´æ–°è¿›åº¦"""
    if progress_callback:
        progress_callback(step_name, progress)


def check_stop():
    """æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢"""
    return stop_requested


INFERENCE_TYPE = "https"  # 'https' æˆ– 'grpc_standard'
IMAGES_DIR = ""  # è¾“å…¥å›¾ç‰‡ç›®å½•
GT_JSONS_DIR = ""  # çœŸå€¼æ ‡æ³¨ç›®å½•


def get_dynamic_report_paths(inference_type):
    """æ ¹æ®æ¨ç†ç±»å‹ç”ŸæˆåŠ¨æ€æŠ¥å‘Šè·¯å¾„"""
    base_path = f"{inference_type}/reports"
    return {
        "eval_output_file": f"{base_path}/evaluation_report.csv",
        "viz_output_dir": f"{base_path}/visualization_results",
        "semseg_eval_output_file": f"{base_path}/semseg_eval.csv",
        "semseg_viz_output_dir": f"{base_path}/semseg_vis_masks",
    }


def update_config_with_dynamic_paths(config, inference_type):
    """ä½¿ç”¨åŠ¨æ€è·¯å¾„æ›´æ–°é…ç½®"""
    paths = get_dynamic_report_paths(inference_type)

    # æ›´æ–°è¯„ä¼°é…ç½®
    if "EVAL_CONFIG" in config:
        config["EVAL_CONFIG"]["eval_output_file"] = paths["eval_output_file"]
        config["EVAL_CONFIG"]["viz_output_dir"] = paths["viz_output_dir"]

    # æ›´æ–°è¯­ä¹‰åˆ†å‰²é…ç½®
    if "SEMSEG_CONFIG" in config:
        config["SEMSEG_CONFIG"]["eval_output_file"] = paths["semseg_eval_output_file"]
        config["SEMSEG_CONFIG"]["viz_output_dir"] = paths["semseg_viz_output_dir"]

    return config


# HTTPS é…ç½® (å½“ INFERENCE_TYPE='https' æ—¶ä½¿ç”¨)
HTTPS_CONFIG = {
    "img_stream_url": "",
    "stream_name": "",
    "access_key": "",
    "secret_key": "",
    "raw_responses_dir": "https/responses",
    "pred_jsons_dir": "https/pred_jsons",
    "max_workers": 1,  # é»˜è®¤ä¸²è¡Œå¤„ç†
}

# æ ‡å‡† gRPC é…ç½® (å½“ INFERENCE_TYPE='grpc_standard' æ—¶ä½¿ç”¨)
GRPC_STANDARD_CONFIG = {
    "grpc_server": "",
    "task_id": "",  # ä»»åŠ¡ID
    "stream_name": "",  # æµåç§°
    "raw_responses_dir": "grpc_standard/responses",
    "pred_jsons_dir": "grpc_standard/pred_jsons",
    "max_workers": 1,  # é»˜è®¤ä¸²è¡Œå¤„ç†
}

# è¯„ä¼°å’Œå¯è§†åŒ–é…ç½®
EVAL_CONFIG = {
    "iou_threshold": 0.5,
    "eval_output_file": "reports/evaluation_report.csv",  # ä¼šè¢«åŠ¨æ€è·¯å¾„è¦†ç›–
    "viz_output_dir": "reports/visualization_results",  # ä¼šè¢«åŠ¨æ€è·¯å¾„è¦†ç›–
    "viz_mode": True,  # True: ç»Ÿè®¡æ¨¡å¼(æ˜¾ç¤ºTP/FP/FN) æˆ– False: æ ‡ç­¾é¢œè‰²æ¨¡å¼
}

# è¯­ä¹‰åˆ†å‰²é…ç½®
SEMSEG_CONFIG = {
    "enabled": False,  # æ˜¯å¦å¯ç”¨è¯­ä¹‰åˆ†å‰²è¯„ä¼°
    "eval_output_file": "reports/semseg_eval.csv",  # ä¼šè¢«åŠ¨æ€è·¯å¾„è¦†ç›–
    "viz_output_dir": "reports/semseg_vis_masks",  # ä¼šè¢«åŠ¨æ€è·¯å¾„è¦†ç›–
    "save_diff_png": False,  # æ˜¯å¦ä¿å­˜å·®åˆ†PNG
    "max_workers": 1,  # é»˜è®¤ä¸²è¡Œå¤„ç†
    "iou_threshold": 0.8,  # IoUç»Ÿè®¡é˜ˆå€¼
}

#  æµç¨‹æ§åˆ¶ - å¯ä»¥è·³è¿‡æŸäº›æ­¥éª¤
STEPS = {
    "run_inference": True,  # æ‰§è¡Œæ¨ç†
    "run_conversion": True,  # æ ¼å¼è½¬æ¢
    "run_evaluation": True,  # æ¨¡å‹è¯„ä¼°
    "run_visualization": True,  # ç»“æœå¯è§†åŒ–
    "run_semseg_evaluation": False,  # è¯­ä¹‰åˆ†å‰²è¯„ä¼°
    "run_semseg_visualization": False,  # è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–
}

# å‘åå…¼å®¹çš„CONFIGå˜é‡
CONFIG = HTTPS_CONFIG  # é»˜è®¤ä½¿ç”¨HTTPSé…ç½®


def get_config():
    """è·å–å½“å‰é…ç½®"""
    if INFERENCE_TYPE == "https":
        return HTTPS_CONFIG
    elif INFERENCE_TYPE == "grpc_standard":
        return GRPC_STANDARD_CONFIG
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨ç†ç±»å‹: {INFERENCE_TYPE}")


def validate_config():
    """éªŒè¯é…ç½®æ˜¯å¦å®Œæ•´"""
    errors = []

    # æ£€æŸ¥åŸºç¡€ç›®å½•é…ç½®
    if not IMAGES_DIR or not os.path.exists(IMAGES_DIR):
        errors.append(f"è¾“å…¥å›¾ç‰‡ç›®å½•æ— æ•ˆ: {IMAGES_DIR}")

    if not GT_JSONS_DIR or not os.path.exists(GT_JSONS_DIR):
        errors.append(f"çœŸå€¼æ ‡æ³¨ç›®å½•æ— æ•ˆ: {GT_JSONS_DIR}")

    # æ£€æŸ¥æ¨ç†ç±»å‹ç‰¹å®šé…ç½®
    if INFERENCE_TYPE == "https":
        if not HTTPS_CONFIG["img_stream_url"]:
            errors.append("HTTPSæ¨ç†URLæœªè®¾ç½®")
        if not HTTPS_CONFIG["stream_name"]:
            errors.append("HTTPSæµåç§°æœªè®¾ç½®")
        if not HTTPS_CONFIG["access_key"]:
            errors.append("HTTPSè®¿é—®å¯†é’¥æœªè®¾ç½®")
        if not HTTPS_CONFIG["secret_key"]:
            errors.append("HTTPSå¯†é’¥æœªè®¾ç½®")
    elif INFERENCE_TYPE == "grpc_standard":
        if not GRPC_STANDARD_CONFIG["grpc_server"]:
            errors.append("æ ‡å‡†gRPCæœåŠ¡å™¨åœ°å€æœªè®¾ç½®")
        if not GRPC_STANDARD_CONFIG["task_id"]:
            errors.append("æ ‡å‡†gRPCä»»åŠ¡IDæœªè®¾ç½®")
        if not GRPC_STANDARD_CONFIG["stream_name"]:
            errors.append("æ ‡å‡†gRPCæµåç§°æœªè®¾ç½®")

    # æ£€æŸ¥IoUé˜ˆå€¼
    if not (0 < EVAL_CONFIG["iou_threshold"] <= 1):
        errors.append(f"IoUé˜ˆå€¼æ— æ•ˆ: {EVAL_CONFIG['iou_threshold']}")

    if errors:
        error_msg = "é…ç½®éªŒè¯å¤±è´¥:\n" + "\n".join(f"  - {error}" for error in errors)
        logger.error(error_msg)
        return False, error_msg

    return True, "é…ç½®éªŒè¯é€šè¿‡"


def create_dirs():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    config = get_config()
    dirs = [
        config["raw_responses_dir"],
        config["pred_jsons_dir"],
        EVAL_CONFIG["viz_output_dir"],
    ]

    # æ·»åŠ è¯„ä¼°æŠ¥å‘Šæ–‡ä»¶çš„çˆ¶ç›®å½•
    eval_output_parent = Path(EVAL_CONFIG["eval_output_file"]).parent
    if str(eval_output_parent) != ".":  # ä¸æ˜¯å½“å‰ç›®å½•
        dirs.append(str(eval_output_parent))

    for dir_path in dirs:
        os.makedirs(dir_path, exist_ok=True)
        logger.info(f"âœ“ ç›®å½•: {dir_path}")


def retry_on_failure(max_retries: int = 3, delay: float = 1.0):
    """é‡è¯•è£…é¥°å™¨"""

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = Exception("æœªçŸ¥é”™è¯¯")
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        logger.warning(
                            f"{func.__name__} ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥: {e}, {delay}ç§’åé‡è¯•...",
                        )
                        time.sleep(delay)
                    else:
                        logger.error(f"{func.__name__} æ‰€æœ‰{max_retries}æ¬¡å°è¯•éƒ½å¤±è´¥äº†")
            raise last_exception

        return wrapper

    return decorator


@retry_on_failure(max_retries=2, delay=2.0)
def step_1_https_inference():
    """æ­¥éª¤1: HTTPSæ¨ç†"""
    logger.info("ğŸŒ æ­¥éª¤1: HTTPSæ¨ç†...")

    try:
        # ä¸ä¿®æ”¹å…¨å±€å˜é‡ï¼Œç›´æ¥ä¼ é€’é…ç½®
        from interface.https import https_api

        # æ„é€ é…ç½®å­—å…¸
        config = {
            "img_stream_url": HTTPS_CONFIG["img_stream_url"],
            "stream_name": HTTPS_CONFIG["stream_name"],
            "access_key": HTTPS_CONFIG["access_key"],
            "secret_key": HTTPS_CONFIG["secret_key"],
        }

        # æ‰§è¡Œæ¨ç†ï¼Œä¼ å…¥é…ç½®
        https_api.infer_dir_to_jsons(
            image_dir=IMAGES_DIR,
            out_dir=HTTPS_CONFIG["raw_responses_dir"],
            config=config,
            max_workers=HTTPS_CONFIG["max_workers"],
        )

        logger.info("âœ… HTTPSæ¨ç†å®Œæˆ")
        return True

    except Exception as e:
        logger.error(f"âŒ HTTPSæ¨ç†å¤±è´¥: {e}")
        return False


@retry_on_failure(max_retries=2, delay=1.0)
def step_2_https_conversion():
    """æ­¥éª¤2: HTTPSæ ¼å¼è½¬æ¢"""
    logger.info("ğŸ”„ æ­¥éª¤2: HTTPSæ ¼å¼è½¬æ¢...")

    try:
        from interface import convert2labelme

        # è®¾ç½®å‚æ•°
        convert2labelme.RAW_JSON_DIR = HTTPS_CONFIG["raw_responses_dir"]
        convert2labelme.IMAGE_DIR = IMAGES_DIR
        convert2labelme.LABELME_OUTPUT_DIR = HTTPS_CONFIG["pred_jsons_dir"]
        convert2labelme.MAX_WORKERS = HTTPS_CONFIG["max_workers"]

        # æ‰§è¡Œè½¬æ¢
        convert2labelme.batch_convert()

        logger.info("âœ… HTTPSæ ¼å¼è½¬æ¢å®Œæˆ")
        return True

    except Exception as e:
        logger.error(f"âŒ HTTPSæ ¼å¼è½¬æ¢å¤±è´¥: {e}")
        return False


@retry_on_failure(max_retries=2, delay=2.0)
def step_1_grpc_standard_inference():
    """æ­¥éª¤1: æ ‡å‡†gRPCæ¨ç†"""
    logger.info("âš¡ æ­¥éª¤1: æ ‡å‡†gRPCæ¨ç†...")

    try:
        from interface.grpc import grpc_api

        # è®¾ç½®å‚æ•°
        grpc_api.SERVER_ADDRESS = GRPC_STANDARD_CONFIG["grpc_server"]
        grpc_api.TASK_ID = GRPC_STANDARD_CONFIG["task_id"]  # è®¾ç½®ä»»åŠ¡ID
        grpc_api.STREAM_NAME = GRPC_STANDARD_CONFIG["stream_name"]  # è®¾ç½®æµåç§°
        grpc_api.IMAGE_DIR = IMAGES_DIR
        grpc_api.OUTPUT_DIR = GRPC_STANDARD_CONFIG["raw_responses_dir"]
        grpc_api.MAX_WORKERS = GRPC_STANDARD_CONFIG["max_workers"]

        # æ‰§è¡Œæ¨ç†
        channel, stub = grpc_api.create_grpc_stub(GRPC_STANDARD_CONFIG["grpc_server"])
        try:
            grpc_api.save_all_images_multithread(
                IMAGES_DIR,
                GRPC_STANDARD_CONFIG["raw_responses_dir"],
                stub,
                GRPC_STANDARD_CONFIG["max_workers"],
            )
        finally:
            channel.close()

        logger.info("âœ… æ ‡å‡†gRPCæ¨ç†å®Œæˆ")
        return True

    except Exception as e:
        logger.error(f"âŒ æ ‡å‡†gRPCæ¨ç†å¤±è´¥: {e}")
        return False


@retry_on_failure(max_retries=2, delay=1.0)
def step_2_grpc_standard_conversion():
    """æ­¥éª¤2: æ ‡å‡†gRPCæ ¼å¼è½¬æ¢"""
    logger.info("ğŸ”„ æ­¥éª¤2: æ ‡å‡†gRPCæ ¼å¼è½¬æ¢...")

    try:
        from interface import convert2labelme

        # è®¾ç½®å‚æ•°
        convert2labelme.RAW_JSON_DIR = GRPC_STANDARD_CONFIG["raw_responses_dir"]
        convert2labelme.IMAGE_DIR = IMAGES_DIR
        convert2labelme.LABELME_OUTPUT_DIR = GRPC_STANDARD_CONFIG["pred_jsons_dir"]
        convert2labelme.MAX_WORKERS = GRPC_STANDARD_CONFIG["max_workers"]

        # æ‰§è¡Œè½¬æ¢
        convert2labelme.batch_convert()

        logger.info("âœ… æ ‡å‡†gRPCæ ¼å¼è½¬æ¢å®Œæˆ")
        return True

    except Exception as e:
        logger.error(f"âŒ æ ‡å‡†gRPCæ ¼å¼è½¬æ¢å¤±è´¥: {e}")
        return False


@retry_on_failure(max_retries=1, delay=1.0)
def step_3_evaluation():
    """æ­¥éª¤3: æ¨¡å‹è¯„ä¼°"""
    logger.info("ğŸ“Š æ­¥éª¤3: æ¨¡å‹è¯„ä¼°...")

    try:
        from model_evaluation import eval_report

        config = get_config()

        # æ‰§è¡Œè¯„ä¼°
        eval_report.evaluate(
            gt_dir=GT_JSONS_DIR,
            pred_dir=config["pred_jsons_dir"],
            iou_thr=EVAL_CONFIG["iou_threshold"],
            out_csv=EVAL_CONFIG["eval_output_file"],
        )

        logger.info(f"âœ… æ¨¡å‹è¯„ä¼°å®Œæˆï¼ŒæŠ¥å‘Š: {EVAL_CONFIG['eval_output_file']}")
        return True

    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
        return False


@retry_on_failure(max_retries=1, delay=1.0)
def step_4_visualization():
    """æ­¥éª¤4: ç»“æœå¯è§†åŒ–"""
    logger.info("ğŸ¨ æ­¥éª¤4: ç»“æœå¯è§†åŒ–...")

    try:
        import os

        from model_evaluation import vision

        config = get_config()

        # è®¾ç½®å¿…è¦çš„å…¨å±€å˜é‡
        vision.IMAGE_FOLDER = IMAGES_DIR
        vision.GT_FOLDER = GT_JSONS_DIR
        vision.PRED_FOLDER = config["pred_jsons_dir"]
        vision.IOU_THRESHOLD = EVAL_CONFIG["iou_threshold"]

        # è®¾ç½®è¾“å‡ºç›®å½•
        output_base = EVAL_CONFIG["viz_output_dir"]
        vision.CORRECT_DIR = os.path.join(output_base, "correct")
        vision.ERROR_DIR = os.path.join(output_base, "error")

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(vision.CORRECT_DIR, exist_ok=True)
        os.makedirs(vision.ERROR_DIR, exist_ok=True)

        # æ‰§è¡Œå¯è§†åŒ–
        vision.visualize_all(
            gt_folder=GT_JSONS_DIR,
            pred_folder=config["pred_jsons_dir"],
            iou_thr=EVAL_CONFIG["iou_threshold"],
            stats_mode=EVAL_CONFIG["viz_mode"],
            max_workers=EVAL_CONFIG["max_workers"],
        )

        logger.info(f"âœ… ç»“æœå¯è§†åŒ–å®Œæˆï¼Œè¾“å‡º: {EVAL_CONFIG['viz_output_dir']}")
        return True

    except Exception as e:
        logger.error(f"âŒ ç»“æœå¯è§†åŒ–å¤±è´¥: {e}")
        return False


@retry_on_failure(max_retries=1, delay=1.0)
def step_5_semseg_evaluation():
    """æ­¥éª¤5: è¯­ä¹‰åˆ†å‰²IoUè¯„ä¼°"""
    logger.info("ğŸ”¬ æ­¥éª¤5: è¯­ä¹‰åˆ†å‰²IoUè¯„ä¼°...")

    try:
        if not SEMSEG_CONFIG["enabled"]:
            logger.info("âš ï¸ è¯­ä¹‰åˆ†å‰²è¯„ä¼°æœªå¯ç”¨ï¼Œè·³è¿‡")
            return True

        # åŠ¨æ€å¯¼å…¥è¯­ä¹‰åˆ†å‰²æ¨¡å—
        import sys
        from pathlib import Path

        semseg_path = Path(__file__).parent / "semantic_segmentation"
        if str(semseg_path) not in sys.path:
            sys.path.append(str(semseg_path))

        from semantic_segmentation import ss_IoU

        config = get_config()
        raw_responses_dir = config["raw_responses_dir"]  # ç›´æ¥ä½¿ç”¨åŸå§‹æ¨ç†å“åº”
        eval_output = SEMSEG_CONFIG["eval_output_file"]

        logger.info("ğŸ”¬ å¼€å§‹è¯­ä¹‰åˆ†å‰²IoUè¯„ä¼°")
        logger.info(f"   æ¨ç†å“åº”ç›®å½•: {raw_responses_dir}")
        logger.info(f"   çœŸå€¼ç›®å½•: {GT_JSONS_DIR}")
        logger.info(f"   è¾“å‡ºæ–‡ä»¶: {eval_output}")

        if check_stop():
            logger.warning("âš ï¸ ç”¨æˆ·è¯·æ±‚åœæ­¢æ‰§è¡Œ")
            return False

        # è®¾ç½®è¯­ä¹‰åˆ†å‰²æ¨¡å—çš„é…ç½®
        ss_IoU.PRED_JSON_DIR = raw_responses_dir
        ss_IoU.GT_JSON_DIR = GT_JSONS_DIR
        ss_IoU.OUTPUT_XLSX = eval_output
        ss_IoU.SAVE_DIFF_PNG = SEMSEG_CONFIG["save_diff_png"]
        ss_IoU.MAX_WORKERS = SEMSEG_CONFIG["max_workers"]
        ss_IoU.IOU_THRESHOLD = SEMSEG_CONFIG["iou_threshold"]

        # æ‰§è¡Œè¯­ä¹‰åˆ†å‰²è¯„ä¼°
        ss_IoU.main()

        logger.info("âœ… è¯­ä¹‰åˆ†å‰²IoUè¯„ä¼°å®Œæˆ")
        return True

    except Exception as e:
        logger.error(f"âŒ è¯­ä¹‰åˆ†å‰²è¯„ä¼°å¤±è´¥: {e}")
        import traceback

        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False


@retry_on_failure(max_retries=1, delay=1.0)
def step_6_semseg_visualization():
    """æ­¥éª¤6: è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–"""
    logger.info("ğŸ¨ æ­¥éª¤6: è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–...")

    try:
        if not SEMSEG_CONFIG["enabled"]:
            logger.info("âš ï¸ è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–æœªå¯ç”¨ï¼Œè·³è¿‡")
            return True

        # åŠ¨æ€å¯¼å…¥è¯­ä¹‰åˆ†å‰²æ¨¡å—
        import sys
        from pathlib import Path

        semseg_path = Path(__file__).parent / "semantic_segmentation"
        if str(semseg_path) not in sys.path:
            sys.path.append(str(semseg_path))

        from semantic_segmentation import ss_visualization

        config = get_config()
        raw_responses_dir = config["raw_responses_dir"]  # ç›´æ¥ä½¿ç”¨åŸå§‹æ¨ç†å“åº”
        viz_dir = SEMSEG_CONFIG["viz_output_dir"]

        logger.info("ğŸ¨ å¼€å§‹è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–")
        logger.info(f"   æ¨ç†å“åº”ç›®å½•: {raw_responses_dir}")
        logger.info(f"   å›¾åƒç›®å½•: {IMAGES_DIR}")
        logger.info(f"   è¾“å‡ºç›®å½•: {viz_dir}")

        if check_stop():
            logger.warning("âš ï¸ ç”¨æˆ·è¯·æ±‚åœæ­¢æ‰§è¡Œ")
            return False

        # è®¾ç½®è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–æ¨¡å—çš„é…ç½®
        ss_visualization.PRED_JSON_DIR = raw_responses_dir
        ss_visualization.IMAGE_DIR = IMAGES_DIR
        ss_visualization.VIS_DIR = viz_dir

        # æ‰§è¡Œè¯­ä¹‰åˆ†å‰²å¯è§†åŒ–
        ss_visualization.main()

        logger.info("âœ… è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–å®Œæˆ")
        return True

    except Exception as e:
        logger.error(f"âŒ è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback

        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False


def main():
    start_time = time.time()

    # é‡ç½®åœæ­¢æ ‡å¿—
    reset_stop_flag()

    logger.info("=" * 60)
    logger.info("ğŸš€ å¼€å§‹ä¸€é”®æ‰§è¡Œæ¨ç†æµæ°´çº¿")
    logger.info(f"ğŸ“‹ é…ç½®: {INFERENCE_TYPE.upper()} æ¨¡å¼")
    logger.info("=" * 60)

    update_progress("åˆå§‹åŒ–", 0)

    # éªŒè¯é…ç½®
    is_valid, validation_msg = validate_config()
    if not is_valid:
        logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
        update_progress("é…ç½®é”™è¯¯", 0)
        return False

    logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    create_dirs()
    logger.info("ğŸ“ ç›®å½•é…ç½®:")
    logger.info(f"   è¾“å…¥å›¾ç‰‡: {IMAGES_DIR}")
    logger.info(f"   çœŸå€¼æ ‡æ³¨: {GT_JSONS_DIR}")
    config = get_config()
    logger.info(f"   åŸå§‹å“åº”: {config['raw_responses_dir']}")
    logger.info(f"   é¢„æµ‹ç»“æœ: {config['pred_jsons_dir']}")
    logger.info(f"   è¯„ä¼°æŠ¥å‘Š: {EVAL_CONFIG['eval_output_file']}")
    logger.info(f"   å¯è§†åŒ–å›¾: {EVAL_CONFIG['viz_output_dir']}")

    # æ‰§è¡Œæ­¥éª¤
    success = True

    def log_step_progress(step_name: str, success: bool):
        """è®°å½•æ­¥éª¤è¿›åº¦"""
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        logger.info(f"   {step_name}: {status}")

    # æ­¥éª¤1: æ¨ç†
    if STEPS["run_inference"]:
        if check_stop():
            logger.info("âš ï¸ æ”¶åˆ°åœæ­¢è¯·æ±‚ï¼Œç»ˆæ­¢æ‰§è¡Œ")
            return False

        update_progress("æ­¥éª¤1: æ¨ç†", 25)

        if INFERENCE_TYPE == "https":
            result = step_1_https_inference()
        elif INFERENCE_TYPE == "grpc_standard":
            result = step_1_grpc_standard_inference()
        else:
            logger.error(f"âŒ ä¸æ”¯æŒçš„æ¨ç†ç±»å‹: {INFERENCE_TYPE}")
            result = False

        log_step_progress("æ¨ç†", result)
        success = success and result
        if not result:
            logger.error("æ¨ç†æ­¥éª¤å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return False

    # æ­¥éª¤2: æ ¼å¼è½¬æ¢
    if STEPS["run_conversion"]:
        if check_stop():
            logger.info("âš ï¸ æ”¶åˆ°åœæ­¢è¯·æ±‚ï¼Œç»ˆæ­¢æ‰§è¡Œ")
            return False

        update_progress("æ­¥éª¤2: æ ¼å¼è½¬æ¢", 50)

        if INFERENCE_TYPE == "https":
            result = step_2_https_conversion()
        elif INFERENCE_TYPE == "grpc_standard":
            result = step_2_grpc_standard_conversion()
        else:
            logger.error(f"âŒ ä¸æ”¯æŒçš„æ¨ç†ç±»å‹: {INFERENCE_TYPE}")
            result = False

        log_step_progress("æ ¼å¼è½¬æ¢", result)
        success = success and result
        if not result:
            logger.error("æ ¼å¼è½¬æ¢æ­¥éª¤å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return False

    # æ­¥éª¤3: æ¨¡å‹è¯„ä¼°
    if STEPS["run_evaluation"]:
        if check_stop():
            logger.info("âš ï¸ æ”¶åˆ°åœæ­¢è¯·æ±‚ï¼Œç»ˆæ­¢æ‰§è¡Œ")
            return False

        update_progress("æ­¥éª¤3: æ¨¡å‹è¯„ä¼°", 75)

        result = step_3_evaluation()
        log_step_progress("æ¨¡å‹è¯„ä¼°", result)
        success = success and result
        if not result:
            logger.error("æ¨¡å‹è¯„ä¼°æ­¥éª¤å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return False

    # æ­¥éª¤4: ç»“æœå¯è§†åŒ–
    if STEPS["run_visualization"]:
        if check_stop():
            logger.info("âš ï¸ æ”¶åˆ°åœæ­¢è¯·æ±‚ï¼Œç»ˆæ­¢æ‰§è¡Œ")
            return False

        update_progress("æ­¥éª¤4: ç»“æœå¯è§†åŒ–", 85)

        result = step_4_visualization()
        log_step_progress("ç»“æœå¯è§†åŒ–", result)
        success = success and result
        if not result:
            logger.error("ç»“æœå¯è§†åŒ–æ­¥éª¤å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return False

    # æ­¥éª¤5: è¯­ä¹‰åˆ†å‰²IoUè¯„ä¼°
    if STEPS["run_semseg_evaluation"]:
        if check_stop():
            logger.info("âš ï¸ æ”¶åˆ°åœæ­¢è¯·æ±‚ï¼Œç»ˆæ­¢æ‰§è¡Œ")
            return False

        update_progress("æ­¥éª¤5: è¯­ä¹‰åˆ†å‰²è¯„ä¼°", 90)

        result = step_5_semseg_evaluation()
        log_step_progress("è¯­ä¹‰åˆ†å‰²è¯„ä¼°", result)
        success = success and result
        if not result:
            logger.error("è¯­ä¹‰åˆ†å‰²è¯„ä¼°æ­¥éª¤å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return False

    # æ­¥éª¤6: è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–
    if STEPS["run_semseg_visualization"]:
        if check_stop():
            logger.info("âš ï¸ æ”¶åˆ°åœæ­¢è¯·æ±‚ï¼Œç»ˆæ­¢æ‰§è¡Œ")
            return False

        update_progress("æ­¥éª¤6: è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–", 95)

        result = step_6_semseg_visualization()
        log_step_progress("è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–", result)
        success = success and result
        if not result:
            logger.error("è¯­ä¹‰åˆ†å‰²å¯è§†åŒ–æ­¥éª¤å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return False

    # æ€»ç»“
    total_time = time.time() - start_time

    # è®¾ç½®æœ€ç»ˆè¿›åº¦
    if success:
        update_progress("æ‰§è¡Œå®Œæˆ", 100)
    else:
        update_progress("æ‰§è¡Œå¤±è´¥", 100)

    logger.info("=" * 60)
    if success:
        logger.info("ğŸ‰ æµæ°´çº¿æ‰§è¡ŒæˆåŠŸï¼")
    else:
        logger.error("âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥ï¼")
    logger.info(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")
    logger.info("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
    logger.info(f"   â”œâ”€â”€ {config['raw_responses_dir']}/          # åŸå§‹æ¨ç†å“åº”")
    logger.info(f"   â”œâ”€â”€ {config['pred_jsons_dir']}/            # LabelMeé¢„æµ‹ç»“æœ")
    logger.info(f"   â”œâ”€â”€ {EVAL_CONFIG['eval_output_file']}      # è¯„ä¼°æŠ¥å‘Š")
    logger.info(f"   â””â”€â”€ {EVAL_CONFIG['viz_output_dir']}/        # å¯è§†åŒ–å›¾ç‰‡")
    logger.info("       â”œâ”€â”€ correct/     # æ­£ç¡®é¢„æµ‹çš„å›¾ç‰‡")
    logger.info("       â””â”€â”€ error/       # é”™è¯¯é¢„æµ‹çš„å›¾ç‰‡")
    if not success:
        logger.error("è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é…ç½®ã€‚")
    logger.info("=" * 60)

    return success


def run_inference_pipeline(custom_config=None):
    # å¦‚æœä¼ å…¥äº†è‡ªå®šä¹‰é…ç½®ï¼Œä¸´æ—¶ä½¿ç”¨å®ƒ
    if custom_config:
        # ä¿å­˜åŸå§‹é…ç½®
        original_config = {}

        # å®‰å…¨çš„é…ç½®é¡¹åˆ—è¡¨
        safe_config_keys = [
            "INFERENCE_TYPE",
            "IMAGES_DIR",
            "GT_JSONS_DIR",
            "HTTPS_CONFIG",
            "GRPC_CONFIG",
            "GRPC_STANDARD_CONFIG",
            "EVAL_CONFIG",
            "SEMSEG_CONFIG",
            "STEPS",
        ]

        for key, value in custom_config.items():
            if key in safe_config_keys and key in globals():
                original_config[key] = globals()[key]
                globals()[key] = value
                logger.debug(f"ä¸´æ—¶è®¾ç½®é…ç½®: {key} = {value}")
            else:
                logger.warning(f"å¿½ç•¥ä¸å®‰å…¨çš„é…ç½®é¡¹: {key}")

        try:
            # æ‰§è¡Œä¸»æµç¨‹
            logger.info("ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ‰§è¡Œæµæ°´çº¿")
            result = main()
        except Exception as e:
            logger.error(f"æ‰§è¡Œæµæ°´çº¿æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            result = False
        finally:
            # æ¢å¤åŸå§‹é…ç½®
            for key, value in original_config.items():
                globals()[key] = value
                logger.debug(f"æ¢å¤é…ç½®: {key}")
            logger.info("é…ç½®å·²æ¢å¤")

        return result
    else:
        # ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œä½†æ›´æ–°è·¯å¾„ä¸ºåŠ¨æ€è·¯å¾„
        logger.info("ä½¿ç”¨é»˜è®¤é…ç½®æ‰§è¡Œæµæ°´çº¿ï¼Œåº”ç”¨åŠ¨æ€æŠ¥å‘Šè·¯å¾„")

        # ä¿å­˜åŸå§‹é…ç½®
        original_eval_config = EVAL_CONFIG.copy()
        original_semseg_config = SEMSEG_CONFIG.copy()

        try:
            # æ ¹æ®å½“å‰æ¨ç†ç±»å‹æ›´æ–°è·¯å¾„
            paths = get_dynamic_report_paths(INFERENCE_TYPE)
            globals()["EVAL_CONFIG"]["eval_output_file"] = paths["eval_output_file"]
            globals()["EVAL_CONFIG"]["viz_output_dir"] = paths["viz_output_dir"]
            globals()["SEMSEG_CONFIG"]["eval_output_file"] = paths[
                "semseg_eval_output_file"
            ]
            globals()["SEMSEG_CONFIG"]["viz_output_dir"] = paths[
                "semseg_viz_output_dir"
            ]

            logger.info(f"æŠ¥å‘Šè·¯å¾„è®¾ç½®ä¸º: {INFERENCE_TYPE}/reports/")
            result = main()

        except Exception as e:
            logger.error(f"æ‰§è¡Œæµæ°´çº¿æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            result = False
        finally:
            # æ¢å¤åŸå§‹é…ç½®
            globals()["EVAL_CONFIG"] = original_eval_config
            globals()["SEMSEG_CONFIG"] = original_semseg_config

        return result


if __name__ == "__main__":
    main()
